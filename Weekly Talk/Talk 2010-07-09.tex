\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{rotating}
\usepackage[margin=2cm]{geometry}
\DeclareGraphicsRule{*}{eps}{*}{}
\renewcommand{\baselinestretch}{1.5}
\newtheorem{theorem}{Theorem}
\begin{document}

    \begin{center}
        {\bf Talk on 2010-07-09: The EM-REML algorithm(3)}
    \end{center}
    The simple model:
    \begin{equation*}
        Y=X\gamma+H\beta+e
    \end{equation*}
    where

    $Y:N\times 1$,

    $X:N\times p$,

    $\gamma:p\times 1$, $\gamma$ is the fixed effect,

    $H:N\times q$,

    $\beta:q\times 1$, $\beta\sim MN(0,\tau R)$, \\
    and $e:N\times1$, $e\sim MN(0,\sigma I)$.\\
    Let $U=A^TY$ with the condition that$A^TA=I_{N-p}$ and $AA^T=I-P_X$, we have
    \begin{align*}
        E(U)&=E(A^TY)\\
        &=E(A^TX\gamma+A^TH\beta+A^Te)\\
        &=E(A^TX\gamma)\\
    \end{align*}
    Consider that,
    \begin{align*}
        (A^TX\gamma)^T(A^TX\gamma)&=\gamma^TX^TAA^TX\gamma\\
        &=\gamma^TX^T\underbrace{(I-P_X)}_{0}X\gamma\\
        &=0
    \end{align*}
    Therefore $A^TX\gamma=0$, so $E(U)=0$.\\
    Define Var$(Y)=V=\tau HRH^T+\sigma I$, so we have Var$(U)=A^TVA$.\\
    Since $U$ and $\beta$ are normal distributed, the joint distribution of them is also normal distributed, the covariance of $U$ and $\beta$ is
     \begin{equation*}
     \begin{split}
        Cov(U,\beta)&=Cov(A^TX\gamma+A^TH\beta+A^Te,\quad \beta)\\
        &=Cov(A^TH\beta,\quad \beta)\\
        &=A^THVar(\beta)=\tau A^THR
     \end{split}
    \end{equation*}
    Therefore, the joint distribution of $(U,\beta)^T$ is
    \begin{equation*}
    \begin{pmatrix}
    U\\
    \beta
    \end{pmatrix}
    \sim MN\Big( \mu=\begin{pmatrix}
    0\\
    0
    \end{pmatrix}
    ,\Sigma=\begin{pmatrix}
    A^TVA&\tau A^THR\\
    \tau RH^TA&\tau R
    \end{pmatrix}
    \Big)
    \end{equation*}
    According to $E(\mu_1|\mu_2)=\mu_1+\Sigma_{12}(\Sigma_{22})^{-1}\mu_2$ and $Var(\mu_1|\mu_2)=\Sigma_{11}(\Sigma_{22})^{-1}\Sigma_{21}$.\\
    \begin{align*}
        E(U|\beta)&=0+\tau A^THR\tau^{-1}R^{-1}\beta\\
        &=A^TH\beta\\
        Var(U|\beta)&=A^TVA-\tau A^THR\tau^{-1}R^{-1}\tau RH^TA\\
        &=A^TVA-A^T(\tau HRH^T)A\\
        &=A^T(V-\tau HRH^T)A\\
        &=A^T\cdot \sigma I\cdot A\\
        &=\sigma I
    \end{align*}
    Therefore, we have the conditional distribution of $U|\beta$ which is
    \begin{equation*}
    U|\beta\sim MN(A^TH\beta,\sigma(I-P_X))
    \end{equation*}
    For $\beta|U$, we have
    \begin{align*}
        E(\beta|U)&=0+\tau RH^TA\cdot(A^TVA)^{-1}\cdot A^TY\\
        &=\tau RH^T\cdot A(A^TVA)^{-1}A^T\cdot Y\\
        Var(\beta|U)&=\tau R-\tau RH^TA\cdot(A^TVA)^{-1}\cdot \tau A^THR\\
        &=\tau R-\tau^2 RH^T\cdot A(A^TVA)^{-1}A^T\cdot \tau HR
    \end{align*}
    To show that $A(A^TVA)^{-1}A^T=P=V^{-1}-V^{-1}X(X^TV^{-1}X)^{-1}X^TV^{-1}$, we constructing the $n\times p$ matrix $\mathbf{G=V^{-1}X(X^TV^{-1}X)^{-1}}$ and the $n\times n$ matrix $\mathbf{B=[A|G]}$. First the product,
    \begin{equation*}
    \textbf{B}^T\textbf{B}=\begin{bmatrix}
        \textbf{A}^T\\
        \textbf{G}^T
        \end{bmatrix}
        [\mathbf{A}\quad \mathbf{G}]=\begin{bmatrix}
        \mathbf{A}^T\mathbf{A} \quad \mathbf{A}^T\mathbf{G}\\
        \mathbf{G}^T\mathbf{A} \quad \mathbf{G}^T\mathbf{G}
        \end{bmatrix}
    \end{equation*}
    then the determinant can be rewritten as
    \begin{equation*}
    \begin{split}
    |\textbf{B}|^2&=|\textbf{B}'\textbf{B}|=|\mathbf{A}'\mathbf{A}|\times|\mathbf{G}'\mathbf{G}-\mathbf{G}'\mathbf{A}(\mathbf{A}'\mathbf{A})^{-1}\mathbf{A}'\mathbf{G}|\\
    &=|\textbf{I}|\times|\mathbf{G}'\mathbf{G}-\mathbf{G}'(\mathbf{I-P_X})\mathbf{G}|=|\mathbf{G}'P_\mathbf{X}\mathbf{G}|\\
    &=|(\mathbf{X}'\mathbf{V}^{-1}\mathbf{X})^{-1}\mathbf{X}'\mathbf{V}^{-1}\mathbf{X}(\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\mathbf{V}^{-1}\mathbf{X}(\mathbf{X}'\mathbf{V}^{-1}\mathbf{X})^{-1}|=|(\mathbf{X}'\mathbf{X})^{-1}|.
    \end{split}
    \end{equation*}
    \begin{align*}
        (A^TVG)^T(A^TVG)&=G^TVAA^TVG\\
        &=G^TV\underbrace{(I-P_X)VV^{-1}X}_{0}(X^TV^{-1}X)^{-1}\\
        =0
    \end{align*}
    which also says that \textbf{B} is nonsingular.
    \begin{align*}
        V^{-1}&=B(B^TVB)^{-1}B^T\\
        &=[A\quad G]\begin{bmatrix}
    A^TVA&0\\
    0&G^TVG
    \end{bmatrix}\begin{bmatrix}
    A^T\\
    G^T
    \end{bmatrix}\\
    &=A(A^TVA)^{-1}A^T+G(G^TVG)^{-1}G^T\\
    &=A(A^TVA){-1}A^T+G\underbrace{((X^TV^{-1}X)^{-1}X^TV^{-1}VV^{-1}X(X^TV^{-1}X)^{-1})^{-1}}_{X^TV^{-1}X}G^T\\
    &=A(A^TVA){-1}A^T+V^{-1}X(X^TV^{-1}X)^{-1}\cdot X^TV^{-1}X\cdot (X^TV^{-1}X)^{-1}X^TV^{-1}\\
    &=A(A^TVA){-1}A^T+V^{-1}X(X^TV^{-1}X)^{-1}X^TV^{-1}
    \end{align*}
    so we have $A(A^TVA)^{-1}A^T=P=V^{-1}-V^{-1}X(X^TV^{-1}X)^{-1}X^TV^{-1}$.
    Therefore, the expectation and variance of $\beta|U$ can be simplified as
    \begin{align*}
        E(\beta|U)&=\tau RH^TP_XY\\
        Var(\beta|U)&=\tau R-\tau^2 RH^TP_XHR
    \end{align*}
    In another words, we have,
    \begin{equation*}
    \beta|U\sim MN(\tau RH^TP_XY,\tau R-\tau^2 RH^TP_XHR))
    \end{equation*}
    Define $\theta=\{\sigma, \tau\}$, according to the EM algorithm, we need to first compute the expectation of $\log\quad L(\theta^{(t)}|U,\beta)$ given $U$ and $\theta^{(t-1)}$,
    \begin{equation*}
    \begin{split}
    \log L(\theta^{(t)}|U,\beta)&=\log f(U,\beta|\theta^{(t)})\\
    &=\log\{f(U|\beta,\theta^{(t)})f(\beta|\theta^{(t)})\}\\
    &=\log f(U|\beta,\theta^{(t)})+ \log f(\beta|\theta^{(t)})
    %&=\log\underbrace{f(U|\beta,\theta^{(t)})}_{\textrm{independent from }\tau}-\frac{1}{2}\log(|\tau R|)-\frac{1}{2\tau}\beta^TR^{-1}\beta
    \end{split}
    \end{equation*}
    1. Estimate $\tau$
    Take the expectation of $\log L(\theta^{(t)}|U,\beta)$ under $\beta|U,\theta^{(t-1)}$, we have
    \begin{equation*}
        E_{\beta|U,\theta^{(t-1)}}(\log L(\theta^{(t)}|U,\beta))=\log f(U|\beta,\theta^{(t)})-\frac{1}{2} q\log\tau-\frac{1}{2}\log|R|-\frac{1}{2\tau}E_{\beta|U,\theta^{(t-1)}}(\beta^TR^{-1}\beta)
    \end{equation*}
     Since the $E(\varepsilon^T\Lambda\varepsilon)=E(\varepsilon)^T\Lambda E(\varepsilon)+tr(\Lambda Var(\varepsilon))$, (1) can be simplified as
    \begin{equation*}
    \begin{split}
        E_{\beta|U,\theta^{(t-1)}}(\log L(\theta^{(t)}|U,\beta))=&\log f(U|\beta,\theta^{(t)})-\frac{1}{2} q\log\tau-\frac{1}{2}\log|R|\\
        &-\frac{1}{2\tau}\Big[E(\beta|U,\theta^{(t-1)})^TR^{-1} E(\beta|U,\theta^{(t-1)})+tr(R^{-1} Var(\beta|U,\theta^{(t-1)}))\Big]
    \end{split}
    \end{equation*}
    To maximize (2), we let
    \begin{equation*}
    \frac{\partial E_{\beta|U,\theta^{(t-1)}}(\log L(\theta^{(t)}|U,\beta))}{\partial \tau}=0
    \end{equation*}
    It is easily to derive that
    \begin{equation}
        \tau^{(t)}=\frac{1}{q}\Big[E(\beta|U,\theta^{(t-1)})^TR^{-1} E(\beta|U,\theta^{(t-1)})+tr(R^{-1} Var(\beta|U,\theta^{(t-1)}))\Big]
    \end{equation}
    2. Estimate $\sigma$
    We can also get the estimation of $\sigma$ by
    Define
    \begin{align*}
        Q&=E_{\beta|U,\theta^{(t-1)}}(\log L(\theta^{(t)}|U,\beta))\\
        &=-\frac{1}{2}\Big[(N-p)\log\sigma+1+(U-A^TH\beta)^T(U-A^TH\beta)\Big]+\log f(\beta|\theta^{(t)})
    \end{align*}
    If we take the expectation based on $\beta$, then it is applied to the quadratic form $(U-A^TH\beta)^T(U-A^TH\beta)$, but if we  take the expectation based on $e$, then we have,
    \begin{align*}
        E_{\beta|U,\theta^{(t-1)}}((U-A^TH\beta)^T(U-A^TH\beta))&= E_{\beta|U,\theta^{(t-1)}}[(A^Te)^T(A^Te)]\\
        &= E_{\beta|U,\theta^{(t-1)}}[e^Te]
    \end{align*}
    then we can easily get
    \begin{equation*}
        \sigma^{(t)}=\frac{1}{q}\Big[E(\sigma|U,\theta^{(t-1)})^TE(\sigma|U,\theta^{(t-1)})+tr( Var(\sigma|U,\theta^{(t-1)}))\Big]
    \end{equation*}
    just like $\tau$.
    If we still take the expectation on $\beta$, then
    \begin{align*}
        E_\beta[\log(L)]=&E_\beta\Big[-\frac{1}{2}(N-p)\log\sigma+1+U^TU-\beta^TH^TAA^TH\beta+\log f(\beta|\theta^{(t)})\Big]\\
        =&E_\beta\Big[-\frac{1}{2}(N-p)\log\sigma+1+Y^T(I-P_X)Y-\beta^TH^T(I-P_X)^TH\beta \Big]+E_\beta\Big[\log f(\beta|\theta^{(t)})\Big]\\
        =&-\frac{1}{2}\Big[(N-p)\log\sigma+Y^T(I-P_X)Y-(H\tilde{\beta})^T(I-P_X)^T(H\tilde{\beta})+tr(H^T(I-P_X)H Var(\beta|U))\Big]\\
        &+E_\beta\Big[\log f(\beta|\theta^{(t)})\Big]+1\\
    \end{align*}
    Let $\dfrac{\partial Q}{\partial \sigma}=0$, we have
    \begin{equation}
        \sigma^{(t)}=\frac{1}{N-p}\Big[(Y-H\tilde{\beta})^T(I-P_X)(Y-H\tilde{\beta})+tr(H^T(I-P_X)H Var(\beta|U))         \Big]
    \end{equation}
    If the model is
    \begin{equation*}
        Y=X\gamma+H_A\beta_A+H_B\beta_B+e
    \end{equation*}
    where

    $Y:N\times 1$,

    $X:N\times p$,

    $\gamma:p\times 1$, $\gamma$ is the fixed effect,

    $H_A:N\times q_A$,

    $\beta_A:q_A\times 1$, $\beta\sim MN(0,\tau_A R_A)$,

    $H_B:N\times q_B$,

    $\beta_B:q_B\times 1$, $\beta\sim MN(0,\tau_B R_B)$, \\
    construct $H=[H_A H_B]$, $\beta=(\beta_A, \beta_B)^T$ and $R=\begin{bmatrix}\tau_A R_A&0\\0&\tau_B R_B \end{bmatrix} $.
    According to the simple model, we can easily get that
    \begin{equation*}
    \begin{pmatrix}
    U\\
    \beta
    \end{pmatrix}
    \sim MN\Big( \mu=\begin{pmatrix}
    0\\
    0
    \end{pmatrix}
    ,\Sigma=\begin{pmatrix}
    A^TVA& A^THR\\
    RH^TA&\tau R
    \end{pmatrix}
    \Big)
    \end{equation*}
    and
    \begin{align*}
        E(U|\beta)&=A^TH\beta\\
        Var(U|\beta)&=\sigma I_{N-p}\\
        E(\beta|U)&=RH^TPY\\
        Var(\beta|U)&= R-RH^TPHR
    \end{align*}
    The likelihood function is
    \begin{align*}
        \log L(\theta^{(t)}|U,\beta)=&\log f(U,\beta|\theta^{(t)})\\
        =&\log f(U|\beta,\theta^{(t)})+ \log f(\beta|\theta^{(t)})\\
        =&\Big(-\frac{1}{2} \Big)\Big[\log\Big|\begin{bmatrix} \tau_AR_A&0\\0&\tau_BR_B \end{bmatrix} \Big|+(\beta_A\quad\beta_B)^T
        \begin{bmatrix}(\tau_AR_A)^{-1}&0\\0&(\tau_BR_B)^{-1}\end{bmatrix}\begin{bmatrix}\beta_A\\ \beta_B\end{bmatrix}           \Big]\\
        &+\log f(U|\beta,\theta^{(t)})\\
        =&\log f(U|\beta,\theta^{(t)})+ \log f(\beta_A|\theta^{(t)})+ \log f(\beta_B|\theta^{(t)})\\
    \end{align*}
    so the estimation of $\theta$ is
    \begin{align}
    \tau^{(t)}_A=&\frac{1}{q_A}\Big[E(\beta_A|U,\theta^{(t-1)})^TR_A^{-1} E(\beta_A|U,\theta^{(t-1)})+tr(R_A^{-1} Var(\beta_A|U,\theta^{(t-1)}))\Big]\\
    \tau^{(t)}_B=&\frac{1}{q_B}\Big[E(\beta_B|U,\theta^{(t-1)})^TR_B^{-1} E(\beta_B|U,\theta^{(t-1)})+tr(R_B^{-1} Var(\beta_B|U,\theta^{(t-1)}))\Big]\\
    \sigma^{(t)}=&\frac{1}{N-p}\Big[(Y-H\tilde{\beta})^T(I-P_X)(Y-H\tilde{\beta})+tr(H^T(I-P_X)H Var(\beta|U))         \Big]
    \end{align}
\end{document}
